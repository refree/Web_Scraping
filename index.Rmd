---
title: "R을 활용하여 웹데이터 수집하기"
output: github_document
---
#### 참고문헌은 다음과 같습니다. 
 - [박찬엽 블로그](https://mrchypark.github.io/getWebR)
 - **박찬엽**님, 감사합니다. 많은 도움 받고 있습니다. 

## 웹에서 데이터 가져오기

텍스트 데이터 분석에 앞서 데이터 수집의 단계를 거치게 됩니다. 

오늘은 다음 영화 리뷰 사이트에서 최근 개봉한 [남산의 부장들](https://movie.daum.net/moviedb/main?movieId=122091)의 영화 **리뷰**를 수집하여 분석하도록 하겠습니다. 

우선, 사용할 패키지를 설치하고 호출합니다. 
'httr','rvest', 'KoNLP','stringr','tm','qgraph','xml2' 패키지가 필요합니다

```{r package}
#install.packages(c('httr','rvest','KoNLP','stringr','tm','sna','xml2'))

library(rvest);library(httr);library(KoNLP);library(stringr); library(tm);library(sna);library(xml2)
```

### 스크래핑할 URL 알려주기


```{r url_}
url_base <- 'https://movie.daum.net/moviedb/grade?movieId=122091&type=netizen&page='

```

### 빈공간 만들기 
```{r save_room}
all.reviews <- c() 
```

### for 문을 이용하여 리뷰 수집하기
총 리뷰 수 확인하고 반복문 횟수 정하기
url_base의 뒤에 페이지를 1~30 리뷰 페이지 까지 증가
```{r count}
for(page in 1:30){                                         #예시로 20까지만 코딩함. 리뷰 갯수에 따라 달라짐.
  url <- paste(url_base, page, sep='', encoding="euc-kr")  
  htxt <- read_html(url)                                   #html 코드 불러오기
  table <- html_nodes(htxt, '.review_info')                #리뷰가 있는 위치 찾아 들어가기 
  content <- html_nodes(table, '.desc_review')             
  reviews <- html_text(content)                            #실제 리뷰의 text 파일만 추출
  if( length(reviews) == 0 ){ break }                      
  reviews <- str_trim(reviews)                             #앞뒤 공백문자 제거  
  all.reviews <- c(all.reviews, reviews)                   #결과값 저장
  print(page)
  }
```

### 스크래핑 결과 확인 
```{r show_result}
head(all.reviews)
```

### 결과를 텍스트 파일로 저장
```{r save_file}
write.table(all.reviews,'namsan.txt')
```
